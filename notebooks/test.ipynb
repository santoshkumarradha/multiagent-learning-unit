{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_api= open(\"../openai_api_key.key\", \"r\").read()\n",
    "from agents import Agent, OpenAIChatGPT, set_global_llm, set_live_verbosity\n",
    "\n",
    "set_live_verbosity(2)\n",
    "openai_llm = OpenAIChatGPT(\n",
    "    api_key=open_ai_api,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "set_global_llm(openai_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/voldemort/Desktop/personal_projects/arc-mlu/notebooks/../notebooks/arc_helper.py:103: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAIACAYAAADzOgrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAg9UlEQVR4nO3dfZBV9X348c/yYICEiK6xYiNriAzSpgxipzVgpI2oGWrijEqISl1bRYhxBpto2sTYZTqaUTITa8hUyIhrGrVqEVKDFYxmg7ShxgYRRI0FFhnc5ak8SIFVMOf3R3677cqu7iN3dz+v18yZce/D2S/X755977n3e29ZRBQBAEAK/Uo9AAAAjh3xBwCQiPgDAEhE/AEAJCL+AAASEX8AAImIPwCARMQfAEAi4g8AIBHxBwCQSJ+Lv6Io2rRNmjSpzfusqqqKoiiivLy8y8Z5wQUXxH333Rfr1q2LI0eORG1tbZftm7brjvnSaMKECbF48eLYtm1bNDQ0RG1tbcyfPz9OO+20Do938ODBUVVV1a7xfPOb34x/+Zd/iW3btkVRFFFVVdXh708OveE4Onjw4Ljhhhti+fLlUVdXF2+99VasXr06Zs2aFf369blfbT1aXz+Ojh49Ou6666548cUX46233oq6urpYunRpnH322R0eQ6kNKPUAutr06dObfX311VfHhRdeeNTlr7766rEc1lGuvPLKmDZtWqxevTrq6upKOpbMumu+3HjjjXHPPffEpk2bYt68eVFfXx9jxoyJ6667LqZNmxZTpkyJVatWtXu8Q4YMiTlz5sScOXNixYoVbbrPHXfcEfX19fHiiy/G5z73uXZ/T/LpDcfRkSNHxrx58+LZZ5+N7373u/HWW2/FRRddFPfee2+cc845cc0115RsbNn09ePoddddF9dee208/vjj8Q//8A9x/PHHx8yZM+M//uM/4nOf+1w8++yz7R5DT1D05W3evHlFURQfeLvBgwe3el1VVVVRFEVRXl7eZeMaPnx4MWDAgCIiip/85CdFbW1tyR8rW9fMlwkTJhRHjhwpVqxYcdTtRo4cWdTX1xdvvvlmMWzYsHaPr7y8vCiKoqiqqmrzfSoqKjp8X5stomceR8vLy4vf+73fO+ryhQsXFkVRFJ/85CdL/rhl3fracXT8+PHFhz/84WaXnXjiicX27duLlStXlvzx7siW8tx4TU1NrFu3LsaPHx8rVqyIAwcOxLe//e0O7WPMmDHxs5/9LA4cOBBbt26NW265pU33r6+vjyNHjnRk+Bxj7Z0vt912WxRFEZWVlXHo0KFm123atCm+/vWvx6mnnhozZ85s9j1qamqO2ld1dXXTSwIqKipi165dERExZ86cpqdSPuhp3DfeeKPN/1Zoq1IfR//7v/87XnnllaMuX7JkSUREjBkzpl1joXv15uPo6tWr48CBA80u2717d6xcubLXzrOU8RcRUV5eHk899VSsWbMmbrrpphYnzAc54YQTYtmyZfHSSy/F1772tXjttddi7ty5nlrrg9o6XwYPHhznn39+rFy5MjZv3tzibR599NFoaGiIiy++uF1j2LlzZ8yaNSsiIhYvXhzTp0+P6dOnx+LFi9u1H+gqPfE4esopp0RENP2Cp+foa8fRU045pdfOsz73mr+2Gj58eMycOTN+8IMfdHgfv/u7vxt//ud/Hg8++GBERCxcuDDeeOONuPbaa2PZsmVdNVR6gLbOl1GjRsXAgQPjpZdeavU277zzTvz6179u91+MBw8ejEWLFsX8+fNj7dq18dBDD7Xr/tDVetpxdODAgXHTTTfFpk2b4oUXXujwmOgefek4eu6558anP/3puP322zt0/1JLG38NDQ1RXV3dqX3s37+/6YAVEXH48OH45S9/GSNHjuzs8Ohh2jpfhg4dGhG/nRvvZ//+/fHRj360S8YGpdLTjqPf//734/d///djypQp8e6773ZqXHS9vnIc/djHPhYPP/xw1NbWxty5c4/59+8KaZ/2ffPNN+Pw4cOd2sfWrVuPumzPnj1xwgkndGq/9DxtnS+NB6vGg1drhg4d+oEHNujpetJx9Oabb47rr78+vvWtb8VTTz3VqTHRPfrCcXTIkCGxdOnSGDp0aFxyySVHvRawt0gbf+99AWlHtPaXZVlZWaf3Tc/S1vmyYcOGOHz4cIwdO7bV2xx33HExevToZi9W/+3CuKP179+/fQOFY6inHEcrKyvjrrvuinvvvTfuuOOOTo+J7tHbj6MDBw6MxYsXx9ixY+OSSy6J9evXd8l+SyFt/EF3OHjwYNTU1MR5550XI0aMaPE2X/ziF2PQoEGxdOnSpsv27NkTw4YNO+q2FRUVzb5u7eAGWX3hC1+I++67LxYvXhxf+cpXSj0cukBPPI6WlZXFP/7jP8b5558fV155ZTz33HPt3kdPIv6gi91+++1RVlYWDzzwQAwaNKjZdaeffnrMnTs36urqYsGCBU2Xb9y4Mc4888w46aSTmi4bO3ZsTJw4sdn9Dx48GBHR4gEOsvnMZz4TjzzySDz33HNx1VVX+eOoD+lpx9F58+bFl770pbjhhhua3k6oN0u74KPU/uAP/iC+8IUvRETEGWecEccff3zceuutERHx0ksvNftrht5l5cqVcfPNN8fdd98da9eujQceeCDq6+vjzDPPjBkzZkS/fv1iypQpsXfv3qb73H///fHVr341li9fHgsXLoyTTz45Zs2aFevXr2/2guaGhoZYv359TJs2LV5//fXYvXt3vPzyy+/79MP06dOjoqIihgwZEhER5513XtNc+9GPfhRbtmzpngcCutGIESPiiSeeiKIoYtGiRTF16tRm169duzbWrVtXotHRWT3pODp79uz4yle+Er/4xS/i4MGDcdVVVzW7fsmSJU1B2ZuU/J2mu3Nr6Z3Ga2pqinXr1rV5Hy29M31r+6iurm7Tp3VUVlYWramuri7545Z164r50ride+65xZIlS4odO3YUb7/9drF58+ZiwYIFxYgRI1q8/ZVXXlls2LChaGhoKFavXl1ccMEFLc6nc845p3jhhReKhoaGNr1LfU1NTatzbdKkSSV/zG09f+uJx9FJkya1Oq99kk3vny+NW084jlZXV7/vXGv8FKXetJX9//8AACABr/kDAEhE/AEAJCL+AAASEX8AAImIPwCARMQfAEAi4g8AIJE2f8LH5LLLu3Mc9GLPFIvafZ/2zqfldWtavPyiU8cd03105X76mq56XDoyn3oLx1FacyyOo+TxQfPJmT8AgETEHwBAIuIPACAR8QcAkEibF3wAAD1Ha4usoP/w97/emT8AgETEHwBAIuIPACAR8QcAkIj4AwBIxGrfdmhpZVX2j/Si43rDSj3zG3ouP5+0bsP7XuvMHwBAIuIPACAR8QcAkIj4AwBIRPwBACRitW87WFlFdyvVHOsNK4+BtvHznEdHf2c48wcAkIj4AwBIRPwBACQi/gAAErHgAwASsGix9+rqRTzO/AEAJCL+AAASEX8AAImIPwCARMQfAEAiVvseY62t2LEKi44wn4DO8nFwPcexOnY78wcAkIj4AwBIRPwBACQi/gAAEhF/AACJWO17jFmFSVcyn4Du4NjS/Uq5ytqZPwCARMQfAEAi4g8AIBHxBwCQiPgDAEjEal8AoE18DnD79cSV0878AQAkIv4AABIRfwAAiYg/AIBExB8AQCJW+/ZSra246omrimg7K+mA3sjvnt51/HbmDwAgEfEHAJCI+AMASET8AQAkIv4AABKx2reXsrKq9/P/EOjretMK2LbqC8duZ/4AABIRfwAAiYg/AIBExB8AQCLiDwAgEat9AYBjqjesmO2LK5UbOfMHAJCI+AMASET8AQAkIv4AABIRfwAAiVjtC12kL68Mg1Jo7WeqN6wUpWNKcRzNOJ+c+QMASET8AQAkIv4AABIRfwAAiVjwAe2U8cXBUAp+1mjUFXPBorz/5cwfAEAi4g8AIBHxBwCQiPgDAEhE/AEAJGK1LwDHTEsrLq3qpaPMp45x5g8AIBHxBwCQiPgDAEhE/AEAJCL+AAASsdqX9HzeY8/Sf3ipR0B3shKTrmQ+dYwzfwAAiYg/AIBExB8AQCLiDwAgEfEHAJCI1b6kYVVYb7Gh1AOgHVpbLe/nja7kXRm6ljN/AACJiD8AgETEHwBAIuIPACAR8QcAkIjVvgB0mFW9dCXz6dhw5g8AIBHxBwCQiPgDAEhE/AEAJCL+AAASsdqXXs3nPfY9/YeXegRAd3PsLi1n/gAAEhF/AACJiD8AgETEHwBAIuIPACARq33pFXzeYyYbSj0AoIs4dvdMzvwBACQi/gAAEhF/AACJiD8AgETEHwBAIlb7AgCd4rN6exdn/gAAEhF/AACJiD8AgETEHwBAIhZ8UBJeHExr+g8v9QiA1vi4tr7BmT8AgETEHwBAIuIPACAR8QcAkIj4AwBIxGpfSsKKMVq3odQDgPS8I0Pf5swfAEAi4g8AIBHxBwCQiPgDAEhE/AEAJGK1LwAk5t0X8nHmDwAgEfEHAJCI+AMASET8AQAkIv4AABIpi4ii1IMAAODYcOYPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkIj4AwBIRPwBACTS5+KvKIo2bZMmTWrzPquqqqIoiigvL++ycX7jG9+IVatWxY4dO+LQoUPx+uuvx9133x0nnXRSl30PPlh3zJdGEyZMiMWLF8e2bduioaEhamtrY/78+XHaaad1eLyDBw+OqqqqNo9n+PDh8aMf/Shee+21eOutt2LPnj3x/PPPx9VXX93hMdC3defPxHu1dz5PmjQpiqKIyy67rNPfm67Rk+dLo9NOOy3uvffeqK2tjYaGhti+fXssWbIkJkyY0KnxfPnLX47KyspO7aNUBpR6AF1t+vTpzb6++uqr48ILLzzq8ldfffVYDusoZ599dqxZsyYeeeSR2L9/f4wZMyZmzJgRf/Znfxbjxo2LgwcPlnR8WXTXfLnxxhvjnnvuiU2bNsW8efOivr4+xowZE9ddd11MmzYtpkyZEqtWrWr3eIcMGRJz5syJOXPmxIoVKz7w9ieddFJ8/OMfj0WLFsWWLVti4MCBccEFF8QPf/jDGD16dNx6663tHgN927E8hrZ3PtPz9PT5MmHChPjXf/3XiIi477774pVXXolTTjklrrnmmli5cmXMnj07vv/973doPDfccEPs2rUrfvjDH3bo/qVW9OVt3rx5RVEUH3i7wYMHt3pdVVVVURRFUV5e3q1jvfTSS4uiKIpp06aV/HHLunXFfJkwYUJx5MiRYsWKFUfdbuTIkUV9fX3x5ptvFsOGDWv3+MrLy4uiKIqqqqpO/TufeOKJYv/+/UW/fv1K/pjbevbW1p+Jjmztnc+TJk0qiqIoLrvsspI/LraWt540X4YNG1bU1dUV9fX1xciRI5tdN2jQoGLFihXFkSNHik9/+tMdGs+6deuKmpqakj/mHdn63NO+bVFTUxPr1q2L8ePHx4oVK+LAgQPx7W9/u0P7GDNmTPzsZz+LAwcOxNatW+OWW27p8Lg2b94cERHDhg3r8D7oeu2dL7fddlsURRGVlZVx6NChZtdt2rQpvv71r8epp54aM2fObPY9ampqjtpXdXV11NbWRkRERUVF7Nq1KyIi5syZ0/R0SlVVVbv/TZs3b44hQ4bEcccd1+77QllZWcyePTtefvnlOHToUGzbti3mz59/1LHr7LPPjmXLlsXOnTvj4MGDsWnTpli4cGFEdN18bnxZzic/+cmorq6OPXv2xN69e+P++++PwYMHd8m/l84p1XyZOXNmDB8+PG655ZbYtGlTs+saGhqisrIyiqKIv/3bv226vHE+vVfjbSsqKiIiora2Nj71qU/Fn/zJnzSNpaVjeE/V5572bavy8vJ46qmn4pFHHokHH3wwtm/f3u59nHDCCbFs2bJYvHhxPPbYY3H55ZfH3LlzY926dbFs2bI2j2PAgAExatSouPPOO+PIkSPx85//vN1joXu1db4MHjw4zj///Fi5cmVTzL/Xo48+Gj/4wQ/i4osvjrvuuqvNY9i5c2fMmjUr5s+fH4sXL47FixdHRMTatWs/8L6DBg2KD3/4w/GRj3wkJk2aFH/xF38Rq1atioaGhjZ/f2i0YMGCuOaaa6K6ujq+973vxSc+8Ym48cYb46yzzoqJEyfGkSNH4mMf+1g8/fTTsXPnzrjzzjtj7969cfrpp8ell14aEZ2bzy157LHHora2Nr7xjW/E+PHjY8aMGbFjx474m7/5my77d9MxpZovn//85+PQoUPx2GOPtXj95s2b49/+7d/is5/9bAwaNKhdx8Obbrop5s2bF//zP/8Td9xxR0REhzqilEp++rE7t5ZOQdfU1BRFURTXX399m/bR0tO+jfuYPn1602UDBw4s6urqin/+539u035/53d+p/i/tmzZUkydOrXkj1nmrbPzZezYsUVRFMXdd9/9vrdbs2ZNsWvXrmbfo6WnD6qrq4va2tqmrzv6tO9f//VfN5trP/3pT4uPf/zjJX+8bT1/e+/PxMSJE4uiKIorrrii2e0uvPDCZpdfcsklRVEUxdlnn93qvrviad/G4/N9993X7LaPP/54sXPnzpI/ftm2njRfdu/eXbz44ovve5u///u/L4qiKD71qU81m0/vvV1lZWVRFEVRUVHRdJmnfXuhhoaGqK6u7tQ+9u/fHw8++GDT14cPH45f/vKXMXLkyDbdf/fu3TF58uS4+OKL47bbbotdu3bFRz7ykU6Nie7R1vkydOjQiPjt3Hg/+/fvj49+9KNdMra2+Kd/+qeYPHlyXHHFFfHQQw9FRHhKjA6ZOnVq7N27N376059GeXl50/arX/0q9u/fH3/6p38aERF79+6NiIiLL744Bgzo/ieZ5s+f3+zrlStXxkknndT0M0lplHK+DB06tE3H4og4psfjniDt075vvvlmHD58uFP72Lp161GX7dmzJ8aOHdum+x8+fDieffbZiIh48skn49lnn41f/OIXsWPHjnjyySc7NTa6VlvnS+OB5IN+4bTloNSVtmzZElu2bImIiEceeSQWLFgQzzzzTIwePdpTv7TLqFGjYtiwYbFz584Wrz/55JMjImLFihWxaNGimDNnTvzVX/1V/PznP48f//jH8fDDD8c777zT5eNqnN+N9uzZExG/fXnOsfxZo7lSzpf9+/e36VjceNtM0sbfe1+I3xHvvvtui5eXlZV1aH+rVq2Kurq6uOqqq8RfD9PW+bJhw4Y4fPjw+/4BcNxxx8Xo0aPjP//zP5suK4qixXnTv3//9g+2DRYtWhTXX399nHfeefH00093y/egb+rXr19s3749rrrqqhav/7+/5KdOnRp//Md/HJ///Ofjoosuiurq6vja174W55xzThw4cKBLx9XVx2O6Rinny6uvvhpnnXVWHHfcca0G5NixY+Odd96J//qv/4qIaHGxR0T3HYtLJW389VSDBg2K448/vtTDoIMOHjwYNTU18dnPfjZGjBhx1NmIiIgvfvGLMWjQoFi6dGnTZXv27Gnx5QKNK8satXZgaq/Gp3zNNdpr48aNMXny5Pj3f//3Np01fv755+P555+Pb33rW3HFFVfEww8/HF/60pdi4cKFXTaf6blKOV+WLl0aEyZMiKlTpza93OX/qqioiM985jPxzDPPNI2t8Yzx8ccfH/v27Wt22/fqzfM37Wv+SmnIkCEtvt7q0ksvjRNPPLHZGSF6n9tvvz3KysrigQceiEGDBjW77vTTT4+5c+dGXV1dLFiwoOnyjRs3xplnntnsE17Gjh0bEydObHb/xjf/buvbAbX2iTHXXntt/OY3v4nVq1e3aT/Q6LHHHosBAwbEbbfddtR1/fv3b/qDoqU5umbNmoiI+NCHPhQR7Z/P9D6lnC8LFiyI7du3x3e+8534xCc+0ey6D33oQ1FdXR1lZWXxd3/3d02Xb9y4MSIizjvvvKbLhgwZ0uIneRw4cKDXzl1n/kpg1KhR8cwzz8Sjjz4ar732WvzmN7+JP/zDP4zp06dHbW1t3HPPPaUeIp2wcuXKuPnmm+Puu++OtWvXxgMPPBD19fVx5plnxowZM6Jfv34xZcqUphc4R0Tcf//98dWvfjWWL18eCxcujJNPPjlmzZoV69evb/ZC5IaGhli/fn1MmzYtXn/99di9e3e8/PLLsX79+hbHcuutt8bEiRNj2bJlsWXLljjxxBPjsssuiz/6oz+K733ve00HOmir5557LubPnx/f/OY3Y9y4cfH000/H4cOHY9SoUTF16tSYPXt2PP7441FZWRk33HBDLFmyJDZu3BhDhw6NGTNmxL59+5o+caG985nep5TzZffu3XH55ZfHk08+GatXrz7qEz7OOOOMmD17drNPW3r66afjjTfeiIULF8Z3vvOdePfdd+Mv//IvY+fOnUed/fvVr34VX/7yl+PWW2+NDRs2xI4dO3rVe/2VfMlxd26tvXXHunXr2ryP1t7qpaV9vPetOVraysvLi/nz5xevvPJKsX///qKhoaH49a9/XXz3u9/t9k8RsXX/fGnczj333GLJkiXFjh07irfffrvYvHlzsWDBgmLEiBEt3v7KK68sNmzYUDQ0NBSrV68uLrjgghbn0znnnFO88MILRUNDwwe+7cHkyZOLJ554oti6dWvx9ttvF/v27StWrlxZVFZWlvyxtvWOrbVPbLjuuuuKF154oThw4ECxb9++4qWXXiruvPPO4pRTTikiohg3blzx0EMPFZs3by4OHTpUbNu2rXjiiSeK8ePHN9tPe+bz+73Vy3uPnS29NYct13xp3CoqKooFCxYUmzdvLt5+++1ix44dxY9//ONi4sSJLd7+rLPOKlatWlU0NDQUmzdvLm666aYW59PJJ59c/OQnPyn27dtXFEXRq972pez//wcAAAl4zR8AQCLiDwAgEfEHAJCI+AMASET8AQAkIv4AABIRfwAAibT5Ez4ml13eneOgF3umWNTu+7xbf0Y3jISOuujUcZ3ex/K6NV2y747Mp97CcZTWOI7SlfoP3/C+1zvzBwCQiPgDAEhE/AEAJNLm1/wBAD1HV7xWl77q/V/zJ/7oURzMuldrizIAyMPTvgAAiYg/AIBExB8AQCLiDwAgEfEHAJCI+AMASET8AQAkIv4AABIRfwAAiYg/AIBExB8AQCLiDwAgEfEHAJCI+AMASET8AQAkIv4AABIZUOoB9HbL69a0ePlFp447puPgf7X2/6Q3M58A6CrO/AEAJCL+AAASEX8AAImIPwCARMQfAEAiVvt2klWYvUdv+H/VF1cqA8eOY0jf1lW/x5z5AwBIRPwBACQi/gAAEhF/AACJWPABAH1Yb1jsRsu6awGPM38AAImIPwCARMQfAEAi4g8AIBHxBwCQiPgDAEhE/AEAJCL+AAASEX8AAImIPwCARMQfAEAi4g8AIJEBpR7AsdDaByP7sGs6wnwCoDdz5g8AIBHxBwCQiPgDAEhE/AEAJCL+AAASSbHa1ypMupL5BEBv5swfAEAi4g8AIBHxBwCQiPgDAEgkxYIPAP5XSx9RaCETHdXaR172db35Z8aZPwCARMQfAEAi4g8AIBHxBwCQiAUfAMn05heq0zv0xTnWlxa2OPMHAJCI+AMASET8AQAkIv4AABIRfwAAiYg/AIBEesRbvbS2fLovLhWndPrSMn0A6Chn/gAAEhF/AACJiD8AgETEHwBAIuIPACCRHrHa16peupL5BACtc+YPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACAR8QcAkEiP+Hg3APq25XVrmn3tYxjpDPOpc5z5AwBIRPwBACQi/gAAEhF/AACJWPABQLfzgny6kvnUOc78AQAk4swfPcp7l+8DAF3LmT8AgETEHwBAIuIPACAR8QcAkIj4AwBIxGpfSsJ7NAFAaTjzBwCQiPgDAEhE/AEAJCL+AAASEX8AAImIPwCARMQfAEAi4g8AIBHxBwCQiPgDAEhE/AEAJCL+AAASEX8AAImIPwCARMQfAEAiA0o9AADoDsvr1jT7+qJTx5VkHBm997GnZxF/lIQDAwCUhqd9AQASEX8AAImIPwCARLzmD4A+yQKPY8Pj3Ps48wcAkIgzf5SEvxQBoDSc+QMASET8AQAkIv4AABIRfwAAiYg/AIBExB8AQCLiDwAgEfEHAJCI+AMASET8AQAkIv4AABIpi4ii1IMAAODYcOYPACAR8QcAkIj4AwBIRPwBACQi/gAAEhF/AACJiD8AgETEHwBAIuIPACCR/wfz4dJ+k7zFfgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebooks.arc_helper import (convert_json_format, generate_string,\n",
    "                                  plot_sample_matrices)\n",
    "\n",
    "directory = \"./ARC-800-tasks/training\"  # Change this to your actual directory path\n",
    "converted_data = convert_json_format(directory)\n",
    "data=generate_string(converted_data)\n",
    "plot_sample_matrices(converted_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlu import MLU\n",
    "\n",
    "mlu = MLU(main_role=\"\"\"\n",
    "                    The goal is to construct the output grid(s) corresponding to the test input grid(s), \n",
    "                    using 3 trials for each test input. 'Constructing the output grid' involves picking \n",
    "                    the height and width of the output grid, then filling each cell in the grid with a symbol \n",
    "                    (integer between 0 and 9, which are visualized as colors). Learn to figure out the \n",
    "                    transformation rules and logic of image(matrix) from few given examples and apply it \n",
    "                    to the final test image(matrix). Analyze the given examples and predict the final \n",
    "                    image(matrix) for the given test image(matrix) and understand how to learn the \n",
    "                    transformation rules and logic of image(matrix) from few given examples to apply it \n",
    "                    to the final test image(matrix).\n",
    "                    \"\"\",\n",
    "    collection_name=\"knowledge_base_v-0.1\",\n",
    "    compress_knowledge=True,\n",
    "    retrival_limit=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Epoch 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|\u001b[32m          \u001b[0m| 0/10 [00:43<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     13\u001b[0m selected_data \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(data, n)\n\u001b[0;32m---> 15\u001b[0m results, train_dtw_scores, test_dtw_scores\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_serial_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_analysis_agent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreasoning_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtesting_analysis_agent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreasoning_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/personal_projects/arc-mlu/notebooks/train_test_helper.py:135\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(dataset, mlu, prompt_key, response_key, epochs, test_size, train_batch_size, test_batch_size, initial_serial_items, logging, training_analysis_agent, testing_analysis_agent)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_data, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m initial_serial_items:\n\u001b[0;32m--> 135\u001b[0m         right_answer, dtw_score \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_item\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmlu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[43manalysis_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_analysis_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m         train_dtw_scores\u001b[38;5;241m.\u001b[39mappend(dtw_score)\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m right_answer:\n",
      "File \u001b[0;32m~/Desktop/personal_projects/arc-mlu/notebooks/train_test_helper.py:51\u001b[0m, in \u001b[0;36mprocess_item\u001b[0;34m(item, mlu, prompt_key, response_key, mode, analysis_agent, logging)\u001b[0m\n\u001b[1;32m     49\u001b[0m prompt \u001b[38;5;241m=\u001b[39m item[prompt_key]\n\u001b[1;32m     50\u001b[0m truth \u001b[38;5;241m=\u001b[39m item[response_key]\n\u001b[0;32m---> 51\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43mmlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtruth\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m: reply[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknowledge_base\u001b[39m\u001b[38;5;124m\"\u001b[39m: reply\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknowledge_update\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo knowledge added\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     57\u001b[0m }\n\u001b[1;32m     59\u001b[0m dtw_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/personal_projects/arc-mlu/notebooks/../mlu/mlu.py:391\u001b[0m, in \u001b[0;36mMLU.call\u001b[0;34m(self, task, expected_output, mode, prune_after, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m oa_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124mRelevant Knowledge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneral_knowledge_str\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[1;32m    388\u001b[0m \u001b[38;5;124mUse the above relevant knowledge to inform your response. If no relevant knowledge is provided, rely on your general understanding.\u001b[39m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_operational_agent(generated_prompt)\n\u001b[0;32m--> 391\u001b[0m oa_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperational_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43moa_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m right_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# need to return the right answer from the feedback agent and add it. we essentially compare ans to output only in training step when expected output is given.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from train_test_helper import train_and_evaluate\n",
    "\n",
    "from logical_agents import logic_concept_reasoning_network\n",
    "\n",
    "reasoning_iterations=4\n",
    "reasoning_agent=lambda prompt: logic_concept_reasoning_network(f\"{prompt}\", max_iterations=reasoning_iterations)\n",
    "\n",
    "set_live_verbosity(0)\n",
    "\n",
    "n = 10 # 10 \n",
    "import random\n",
    "\n",
    "selected_data = random.sample(data, n)\n",
    "\n",
    "results, train_dtw_scores, test_dtw_scores=train_and_evaluate(\n",
    "    dataset=selected_data,  \n",
    "    mlu=mlu,\n",
    "    prompt_key=\"query\",\n",
    "    response_key=\"reply\",\n",
    "    epochs=1,\n",
    "    test_size=0,\n",
    "    train_batch_size=1,\n",
    "    test_batch_size=1,\n",
    "    initial_serial_items=1,\n",
    "    logging=True,\n",
    "    training_analysis_agent = reasoning_agent,\n",
    "    testing_analysis_agent = reasoning_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dtw_scores, test_dtw_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
