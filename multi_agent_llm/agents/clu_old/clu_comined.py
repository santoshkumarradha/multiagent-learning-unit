import uuid
from typing import Any, Dict, List, Optional, Tuple

from pydantic import BaseModel, Field
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from .kmu_combined import KnowledgeManagementUnit

console = Console()


class CombinedCompositeLearnUnit:
    def __init__(
        self,
        llm,
        main_goal: str,
        name: Optional[str] = None,
        storage_goal: Optional[str] = None,
        retrieval_goal: Optional[str] = None,
        compress_knowledge: bool = True,
    ):
        self.llm = llm
        self.main_goal = main_goal
        self.name = name or str(uuid.uuid4())
        self.compress = compress_knowledge

        # Set default goals if not provided
        self.storage_goal = (
            storage_goal
            or f"Store all strategies and knowledge related to tasks to achieve the main goal: {main_goal}. Specifically store if it worked or not."
        )
        self.retrieval_goal = (
            retrieval_goal
            or f"Retrieve relevant strategies and knowledge for the current task based on the main goal: {main_goal}. Specifically extract if it worked or not."
        )

        # Initialize KMU
        self.kmu = KnowledgeManagementUnit(
            llm,
            main_goal=self.main_goal,
            storage_goal=self.storage_goal,
            retrieval_goal=self.retrieval_goal,
            name=f"KMU_{self.name}",
        )

    def _log_step(self, agent_name: str, input_data: str, output_data: str):
        table = Table(title=f"[bold]{agent_name}[/bold]", show_header=False, box=None)
        table.add_row("[cyan]Input:[/cyan]", str(input_data))
        table.add_row("[green]Output:[/green]", str(output_data))
        console.print(Panel(table, expand=False))

    def reason(
        self,
        query: str,
        schema: BaseModel,
        verbose: bool = False,
        _capture_knowledge: bool = False,
    ) -> Any:
        if verbose:
            console.print("[info]Starting Reasoning Process[/info]")

        task_id = self._get_task_id(query)

        # Retrieve knowledge for the task
        retrieved_knowledge = self.kmu.retrieve(query, task_id=task_id, n=50)
        if verbose:
            self._log_step("KMU Retrieval", query, retrieved_knowledge)

        # Generate task-specific prompt
        task_prompt = self._prompt_meta_prompt_agent(
            query, retrieved_knowledge, verbose
        )

        # Execute task using Operational Agent
        result = self._prompt_operational_agent(
            query, retrieved_knowledge, task_prompt, schema, verbose
        )

        if verbose:
            console.print("[info]Reasoning Process Completed[/info]")

        if _capture_knowledge:
            return result, retrieved_knowledge, task_id
        else:
            return result

    def _get_task_id(self, query: str) -> str:
        # Simple placeholder for task identification logic
        return str(hash(query))

    def _prompt_meta_prompt_agent(
        self, task: str, retrieved_knowledge: List[str], verbose: bool = False
    ) -> str:
        system_prompt = f"""You are the Meta-Prompt Agent in the Composite Learning Unit.
Main Goal: {self.main_goal}
Your task is to generate a detailed, task-specific prompt for the Operational Agent based on the given task and retrieved knowledge.
This prompt should guide the Operational Agent in effectively using the knowledge to complete the task."""

        user_prompt = f"Task: {task}\nRetrieved Knowledge: {retrieved_knowledge}\nGenerate a detailed task-specific prompt:"

        class MetaPromptAgentOutput(BaseModel):
            prompt: str = Field(
                ...,
                description="The detailed task-specific prompt generated by the Meta-Prompt Agent",
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=MetaPromptAgentOutput)

        if verbose:
            self._log_step("Meta-Prompt Agent", query, result.prompt)

        return result.prompt

    def _prompt_operational_agent(
        self,
        task: str,
        retrieved_knowledge: List[str],
        task_prompt: str,
        schema: BaseModel,
        verbose: bool = False,
    ) -> Any:
        system_prompt = f"""You are the Operational Agent in the Composite Learning Unit.
Main Goal: {self.main_goal}
Your task is to process the given task using the provided knowledge and following the detailed task-specific prompt.
Before answering, think step by step and explain the reasoning behind the answer, including how the knowledge was used."""

        user_prompt = f"Task: {task}\nKnowledge: {retrieved_knowledge}\nDetailed Task-Specific Prompt: {task_prompt}\nExecute the task:"

        class OperationalAgentOutput(BaseModel):
            explanation: str = Field(
                ..., description="Detailed explanation of the response"
            )
            answer: schema = Field(
                ..., description="The response generated by the Operational Agent"
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=OperationalAgentOutput)

        if verbose:
            self._log_step("Operational Agent", query, str(result))

        return result

    def train(
        self,
        x: Any,
        y: Optional[Any],
        schema: BaseModel,
        verbose: bool = False,
    ) -> Dict[str, Any]:
        if verbose:
            console.print("[info]Starting Training Process[/info]")

        # Perform reasoning and capture knowledge used
        generated_output, retrieved_knowledge, task_id = self.reason(
            x, schema, verbose, _capture_knowledge=True
        )

        # Compare generated output with expected output
        is_equivalent, comparison_explanation = self._prompt_comparison_agent(
            x, self.main_goal, generated_output.answer, y, verbose
        )

        # Generate feedback based on comparison results and knowledge used
        feedback = self._prompt_feedback_agent(
            is_equivalent,
            x,
            self.main_goal,
            generated_output.answer,
            y,
            comparison_explanation,
            retrieved_knowledge,
            verbose,
        )

        # Save feedback to KMU
        self._save_feedback_knowledge(feedback, task_id, verbose)

        if verbose:
            console.print("[info]Training Process Completed[/info]")

        return {
            "generated_output": generated_output.answer,
            "explanation": generated_output.explanation,
            "is_equivalent": is_equivalent,
            "comparison_explanation": comparison_explanation,
            "feedback": feedback,
        }

    def _prompt_comparison_agent(
        self,
        query: str,
        main_goal: str,
        generated_output: Any,
        expected_output: Any,
        verbose: bool = False,
    ) -> Tuple[bool, str]:
        system_prompt = f"""You are the Comparison Agent in the Composite Learning Unit.
Main Goal: {main_goal}
Your task is to compare the generated output with the expected output.
Determine if they are equivalent in meaning, and provide a boolean result and an explanation."""

        user_prompt = f"""Query: {query}
Generated Output: {generated_output}
Expected Output: {expected_output}
Are these outputs equivalent?"""

        class ComparisonAgentOutput(BaseModel):
            is_equivalent: bool = Field(
                ..., description="Boolean indicating if the outputs are equivalent"
            )
            explanation: str = Field(
                ..., description="Explanation of the equivalence decision"
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=ComparisonAgentOutput)

        if verbose:
            self._log_step(
                "Comparison Agent",
                query,
                f"Equivalent: {result.is_equivalent}\nExplanation: {result.explanation}",
            )

        return result.is_equivalent, result.explanation

    def _prompt_feedback_agent(
        self,
        is_positive: bool,
        query: str,
        main_goal: str,
        generated_output: Any,
        expected_output: Any,
        comparison_explanation: str,
        retrieved_knowledge: List[str],
        verbose: bool = False,
    ) -> Dict[str, Any]:
        agent_type = "Positive" if is_positive else "Negative"

        system_prompt = f"""You are the {agent_type} Feedback Agent.
Main Goal: {main_goal}
Your task is to analyze the strategies used and provide feedback."""

        user_prompt = f"""Query: {query}
Generated Output: {generated_output}
Expected Output: {expected_output}
Comparison Explanation: {comparison_explanation}
Retrieved Knowledge: {retrieved_knowledge}
Provide feedback on the strategies used, including:
- Strategy used
- Outcome ('success' or 'failure')
- Reasons"""

        class FeedbackAgentOutput(BaseModel):
            strategy: str = Field(..., description="Description of the strategy used")
            outcome: str = Field(..., description="Outcome ('success' or 'failure')")
            reasons: str = Field(..., description="Reasons for the outcome")

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        feedback = self.llm.generate(query, schema=FeedbackAgentOutput)

        if verbose:
            self._log_step(f"{agent_type} Feedback Agent", query, str(feedback))

        return {
            "strategy": feedback.strategy,
            "outcome": feedback.outcome,
            "reasons": feedback.reasons,
        }

    def _save_feedback_knowledge(
        self,
        feedback: Dict[str, Any],
        task_id: str,
        verbose: bool = False,
    ):
        knowledge_entry = feedback["strategy"]
        metadata = {
            "task_id": task_id,
            "outcome": feedback["outcome"],
            "reasons": feedback["reasons"],
        }
        self.kmu.save(
            knowledge_entry,
            metadata=metadata,
            compress=self.compress,
            align_knowledge=True,
        )
        if verbose:
            console.print(f"Saved feedback to KMU: {knowledge_entry}")

    def print_knowledge(self, verbose: bool = False):
        console.print("[bold]Knowledge Base:[/bold]")
        self.kmu.print_knowledge(verbose)
