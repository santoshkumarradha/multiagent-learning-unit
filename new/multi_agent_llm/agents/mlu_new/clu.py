import threading
import uuid
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List, Optional, Tuple

from pydantic import BaseModel, Field
from rich.color import Color
from rich.console import Console
from rich.panel import Panel
from rich.style import Style
from rich.table import Table
from rich.theme import Theme

my_theme = Theme(
    {
        "info": Style(color=Color.from_rgb(50, 150, 200)),
        "warning": Style(color=Color.from_rgb(200, 150, 50)),
        "error": Style(color=Color.from_rgb(200, 50, 50)),
        "highlight": Style(color=Color.from_rgb(100, 200, 100)),
    }
)

console = Console(theme=my_theme)

from .kmu import KnowledgeManagementUnit


class CompositeLearnUnit:
    def __init__(
        self,
        llm,
        main_goal: str,
        name: Optional[str] = None,
        general_main_goal: Optional[str] = None,
        prompt_main_goal: Optional[str] = None,
        storage_goal: Optional[str] = None,
        retrieval_goal: Optional[str] = None,
        compress_knowledge: bool = True,
    ):
        self.llm = llm
        self.main_goal = main_goal
        self.name = name
        self.compress = compress_knowledge

        # Set default goals if not provided
        self.storage_goal = (
            storage_goal
            or f"Store abstract knowledge and strategies that can be applied to a wide range of tasks and problem-solving scenarios do the main goal - Main goal: {main_goal} in the best way possible. Encourage storing knowledge that can be used in future tasks and not just for the current task."
        )
        self.retrieval_goal = (
            retrieval_goal
            or f"Retrieve relevant abstract knowledge and strategies that can be applied to the current task or query.based on the main role - Main goal: {main_goal}"
        )
        self.general_main_goal = (
            general_main_goal
            or f"Develop and maintain a versatile knowledge base of abstract concepts, patterns, and problem-solving approaches with the main goal: {main_goal} in mind."
        )
        self.prompt_main_goal = (
            prompt_main_goal
            or "Refine strategies for generating effective prompts that can guide reasoning across various types of tasks.Extract relevant information needed to construct high-quality prompts based on the feedback from answering specific task-related query with a given old prompt. - Main goal:  {main_goal}"
        )

        self.general_kmu = KnowledgeManagementUnit(
            llm,
            main_goal=self.general_main_goal,
            storage_goal=self.storage_goal,
            retrieval_goal=self.retrieval_goal,
            name=(
                "GeneralKMU_" + self.name
                if self.name is not None
                else "GeneralKMU_{name}".format(name=str(uuid.uuid4()))
            ),
        )
        self.prompt_kmu = KnowledgeManagementUnit(
            llm,
            main_goal=self.prompt_main_goal,
            storage_goal=self.storage_goal,
            retrieval_goal=self.retrieval_goal,
            name=(
                "PromptKMU_" + self.name
                if self.name is not None
                else "PromptKMU_{name}".format(name=str(uuid.uuid4()))
            ),
        )

    def _log_step(self, agent_name: str, input_data: str, output_data: str):
        table = Table(title=f"[bold]{agent_name}[/bold]", show_header=False, box=None)
        table.add_row("[cyan]Input:[/cyan]", str(input_data))
        table.add_row("[green]Output:[/green]", str(output_data))
        console.print(Panel(table, expand=False))

    def _prompt_meta_prompt_agent(
        self, task: str, prompt_knowledge: str, verbose: bool = False
    ) -> str:
        system_prompt = f"""You are the Meta-Prompt Agent in the Composite Learning Unit.
        Main Goal: {self.prompt_main_goal}
        Your task is to generate a detailed, task-specific prompt for the Operational Agent based on the given task and retrieved prompt knowledge.
        This prompt should guide the Operational Agent in effectively using the general knowledge to complete the task."""

        user_prompt = f"Task: {task}\nPrompt Knowledge: {prompt_knowledge}\nGenerate a detailed task-specific prompt:"

        class MetaPromptAgentOutput(BaseModel):
            prompt: str = Field(
                ...,
                description="The detailed task-specific prompt generated by the Meta-Prompt Agent",
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=MetaPromptAgentOutput)

        if verbose:
            self._log_step("Meta-Prompt Agent", query, result.prompt)

        return result.prompt

    def _prompt_operational_agent(
        self,
        task: str,
        general_knowledge: str,
        task_prompt: str,
        schema: BaseModel,
        verbose: bool = False,
    ) -> Any:
        system_prompt = f"""You are the Operational Agent in the Composite Learning Unit.
        Main Goal: {self.main_goal}
        Your task is to process the given task using the provided general knowledge and following the detailed task-specific prompt.
        Before answering, first think step by step and explain the reasoning behind the answer and how the which parts of the general knowledge and prompt knowledge were used to arrive at the answer. Give detailed reasoning and explanation.
        """

        user_prompt = f"Task: {task}\nGeneral Knowledge: {general_knowledge}\nDetailed Task-Specific Prompt: {task_prompt}\nExecute the task:"

        class OperationalAgentOutput(BaseModel):
            explanation: str = Field(
                ..., description="Detailed explanation of the response"
            )
            answer: schema = Field(
                ...,
                description="The response answer generated by the Operational Agent",
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=OperationalAgentOutput)

        if verbose:
            self._log_step("Operational Agent", query, str(result))

        return result

    def reason(
        self,
        query: str,
        schema: BaseModel,
        verbose: bool = False,
        _capture_knowledge: bool = False,
    ) -> Any:
        if verbose:
            console.print(
                "[info]Starting Reasoning Process[/info]",
            )

        # Retrieve general knowledge
        general_knowledge = self.general_kmu.retrieve(query)
        if verbose:
            self._log_step("General KMU Retrieval", query, general_knowledge)

        # Retrieve prompt knowledge
        prompt_knowledge = self.prompt_kmu.retrieve(query)
        if verbose:
            self._log_step("Prompt KMU Retrieval", query, prompt_knowledge)

        # Generate task-specific prompt
        task_prompt = self._prompt_meta_prompt_agent(query, prompt_knowledge, verbose)

        # Execute task using Operational Agent
        result = self._prompt_operational_agent(
            query, general_knowledge, task_prompt, schema, verbose
        )

        if verbose:
            console.print(
                "[info]Reasoning Process Completed[/info]",
            )

        if _capture_knowledge:
            return result, general_knowledge, prompt_knowledge
        else:
            return result

    def save_general_knowledge(self, knowledge: str, compress: bool = True) -> str:
        return self.general_kmu.save(knowledge, compress)

    def save_prompt_knowledge(self, knowledge: str, compress: bool = True) -> str:
        return self.prompt_kmu.save(knowledge, compress)

    def _prompt_comparison_agent(
        self,
        query: str,
        main_goal: str,
        generated_output: Any,
        expected_output: Any,
        verbose: bool = False,
    ) -> Tuple[bool, str]:
        system_prompt = f"""You are the Comparison Agent in the Composite Learning Unit.
        Main Goal: {main_goal}
        Your task is to compare the generated output with the expected output, considering the query and main goal.
        Determine if they are equivalent, either verbatim or semantically, based on the context of the task.
        
        - Determine if the response matches the expected output exactly
        - If it does not match exactly see if it matches in meaning and intent clearly and unambiguously.
        - Provide an explanation of your comparison, highlighting similarities and differences
        - Return a boolean indicating whether the response is correct and an explanation
        - Do not speculate what might be the reason for the difference, focus on the comparison itself.
        """

        user_prompt = f"""Query: {query}
        Generated Output: {generated_output}
        Expected Output: {expected_output}
        Are these outputs equivalent? Provide a boolean result and a detailed explanation.
        """

        class ComparisonAgentOutput(BaseModel):
            is_equivalent: bool = Field(
                ..., description="Boolean indicating if the outputs are equivalent"
            )
            explanation: str = Field(
                ..., description="Detailed explanation of the equivalence decision"
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=ComparisonAgentOutput)

        if verbose:
            self._log_step(
                "Comparison Agent",
                query,
                f"Equivalent: {result.is_equivalent}\nExplanation: {result.explanation}",
            )

        return result.is_equivalent, result.explanation

    def _prompt_feedback_agent(
        self,
        is_positive: bool,
        query: str,
        main_goal: str,
        generated_output: Any,
        expected_output: Any,
        comparison_explanation: str,
        general_knowledge: str,
        prompt_knowledge: str,
        verbose: bool = False,
    ) -> Dict[str, str]:
        agent_type = "Positive" if is_positive else "Negative"

        if is_positive:
            system_prompt = f"""You are the Positive Feedback Agent in the Composite Learning Unit.
            Main Goal: {main_goal}
            Your task is to provide specific, targeted feedback to reinforce and improve the CLU's performance.
            Focus on two aspects:
            1. Identify and explain which elements of the general knowledge base contributed to the successful outcome.
            2. Analyze how the prompt knowledge effectively guided the reasoning process.
            3. Identify key elements in the reasoning that led to the correct answer
            4. Suggest how this success can be replicated in future tasks
            Provide constructive feedback that encourages building upon this success for future tasks."""
        else:
            system_prompt = f"""You are the Negative Feedback Agent in the Composite Learning Unit.
            Main Goal: {main_goal}
            Your task is to provide specific, targeted feedback to correct and improve the CLU's performance.
            Focus on two aspects:
            1. Identify gaps or inaccuracies in the general knowledge base that led to the incorrect outcome.
            2. Analyze how the knowledge may have misguided the reasoning process.
            3.  Evaluate why the response does not match the expected output
            4.  Identify gaps in knowledge or reasoning that led to the incorrect answer
            5.  Suggest specific changes and improvements to the knowledge base
            6.  Provide strategies to avoid similar mistakes in the future
            7. Identify key elements in the reasoning that led to the incorrect answer
            Provide constructive feedback that addresses these issues and suggests concrete improvements and changes."""

        user_prompt = f"""Query: {query}
        Generated Output: {generated_output}
        Expected Output: {expected_output}
        Comparison Explanation: {comparison_explanation}
        General Knowledge Used: {general_knowledge}
        Prompt Knowledge Used: {prompt_knowledge}
        Provide detailed, through and targeted feedback for improving general knowledge and prompt knowledge:"""

        class FeedbackAgentOutput(BaseModel):
            general_knowledge_feedback: str = Field(
                ..., description="Feedback for improving the general knowledge base"
            )
            prompt_knowledge_feedback: str = Field(
                ..., description="Feedback for improving the prompt knowledge"
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=FeedbackAgentOutput)

        if verbose:
            self._log_step(
                f"{agent_type} Feedback Agent",
                query,
                f"General Knowledge Feedback: {result.general_knowledge_feedback}\nPrompt Knowledge Feedback: {result.prompt_knowledge_feedback}",
            )

        return {
            "general_knowledge_feedback": result.general_knowledge_feedback,
            "prompt_knowledge_feedback": result.prompt_knowledge_feedback,
        }

    def train(
        self,
        x: Any,
        y: Optional[Any] = None,
        schema: BaseModel = None,
        verbose: bool = False,
    ) -> Dict[str, Any]:
        if verbose:
            console.print("[info]Starting Training Process[/info]")

        # Perform reasoning and capture knowledge used
        generated_output, general_knowledge_used, prompt_knowledge_used = self.reason(
            x, schema, verbose, _capture_knowledge=True
        )

        if y is None:
            if verbose:
                console.print(
                    "[warning]No expected output provided. Skipping comparison and feedback.[/warning]"
                )
            return {"generated_output": generated_output}

        # Compare generated output with expected output
        is_equivalent, comparison_explanation = self._prompt_comparison_agent(
            x, self.main_goal, generated_output, y, verbose
        )

        # Generate feedback based on comparison results and knowledge used
        feedback = self._prompt_feedback_agent(
            is_equivalent,
            x,
            self.main_goal,
            generated_output,
            y,
            comparison_explanation,
            general_knowledge_used,
            prompt_knowledge_used,
            verbose,
        )

        # Align and save new knowledge in parallel
        with ThreadPoolExecutor(max_workers=2) as executor:
            general_future = executor.submit(
                self._align_and_save_knowledge,
                "general",
                feedback["general_knowledge_feedback"],
                general_knowledge_used,
                x,
                verbose,
            )
            prompt_future = executor.submit(
                self._align_and_save_knowledge,
                "prompt",
                feedback["prompt_knowledge_feedback"],
                prompt_knowledge_used,
                x,
                verbose,
            )

            general_saved_ids = general_future.result()
            prompt_saved_ids = prompt_future.result()

        if verbose:
            console.print("[info]Training Process Completed[/info]")

        return {
            "generated_output": generated_output,
            "is_equivalent": is_equivalent,
            "comparison_explanation": comparison_explanation,
            "feedback": feedback,
            "new_general_knowledge_ids": general_saved_ids,
            "new_prompt_knowledge_ids": prompt_saved_ids,
        }

    def _prompt_knowledge_alignment_agent(
        self,
        knowledge_type: str,
        feedback: str,
        existing_knowledge: str,
        query: str,
        main_goal: str,
        verbose: bool = False,
    ) -> List[str]:
        system_prompt = f"""You are the Knowledge Alignment Agent for {knowledge_type} knowledge in the Composite Learning Unit.
        Main Goal: {main_goal}
        Your task is to process the feedback and existing knowledge to generate a comprehensive list of knowledge entries that will replace the current knowledge base.
        This list should include:
        1. Modified versions of existing knowledge entries that address the feedback.
        2. New knowledge entries that fill gaps identified in the feedback.
        3. Existing knowledge entries that remain relevant and accurate.
        4. Exclude any existing knowledge that is no longer relevant or accurate based on the feedback.
        5. Always collect diverse list of knowledge entries to ensure comprehensive coverage that is relevant to the main goal.
        6. Favour adding targeted short and relevant knowledge entries over long and verbose entries.
        7. Never memorize the tasks, only extract and save the general and relevant information that can be used in future tasks.
        8. If something methods are tired and is wrong or did not work, always keep the record of that and do not repeat the same mistake again.
        
        Remember, the list you provide will completely replace the existing knowledge, so ensure it is comprehensive and addresses all aspects of the {knowledge_type} knowledge needed to achieve the main goal."""

        user_prompt = f"""Query: {query}
        Existing {knowledge_type} Knowledge: {existing_knowledge}
        Feedback for {knowledge_type} Knowledge: {feedback}
        Generate a comprehensive list of knowledge entries that will replace the existing {knowledge_type} knowledge base:"""

        class KnowledgeAlignmentOutput(BaseModel):
            new_knowledge: List[str] = Field(
                ...,
                description=f"Comprehensive list of {knowledge_type} knowledge entries to replace the existing knowledge base",
            )

        query = self.llm.format_prompt(
            system_prompt=system_prompt, user_prompt=user_prompt
        )
        result = self.llm.generate(query, schema=KnowledgeAlignmentOutput)

        if verbose:
            self._log_step(
                f"{knowledge_type.capitalize()} Knowledge Alignment Agent",
                query,
                f"New Knowledge Entries: {result.new_knowledge}",
            )

        return result.new_knowledge

    def _align_and_save_knowledge(
        self,
        knowledge_type: str,
        feedback: str,
        existing_knowledge: str,
        query: str,
        verbose: bool = False,
    ) -> List[str]:
        new_knowledge_entries = self._prompt_knowledge_alignment_agent(
            knowledge_type, feedback, existing_knowledge, query, self.main_goal, verbose
        )

        if knowledge_type == "general":
            kmu = self.general_kmu
        else:
            kmu = self.prompt_kmu

        # Get the IDs of the existing knowledge entries
        existing_ids = kmu.collection.get()["ids"]

        # Replace the existing knowledge with the new entries
        saved_ids = kmu.replace_knowledge(
            existing_ids, new_knowledge_entries, compress=self.compress
        )

        return saved_ids

    def print_knowledge(self, verbose: bool = False):
        console.print("[bold]General Knowledge:[/bold]")
        self.general_kmu.print_knowledge(verbose)

        console.print("\n[bold]Prompt Knowledge:[/bold]")
        self.prompt_kmu.print_knowledge(verbose)


def example_usage():
    class OperationalAgentOutput(BaseModel):
        response: str = Field(
            ..., description="The response generated by the Operational Agent"
        )

    # Define a mock LLM class for demonstration
    class MockLLM:
        def generate(self, prompt, schema):
            # This is a simplistic mock. In reality, you'd use a real LLM here.
            return schema(
                **{
                    field: f"Mocked {field} based on: {prompt}"
                    for field in schema.__fields__
                }
            )

        def format_prompt(self, system_prompt, user_prompt):
            return f"{system_prompt}\n{user_prompt}"

    # Initialize the CLU
    llm = MockLLM()
    clu = CompositeLearnUnit(
        llm,
        main_goal="Provide accurate and helpful information across various domains",
        general_main_goal="Maintain a comprehensive knowledge base for general reasoning and problem-solving",
        prompt_main_goal="Develop effective prompting strategies for diverse tasks and contexts",
        storage_goal="Store knowledge efficiently, emphasizing clarity and relevance",
        retrieval_goal="Retrieve the most pertinent information for each specific task or query",
    )

    # Manually add some initial knowledge to the KMUs
    clu.save_general_knowledge(
        "Climate change is causing global temperatures to rise, leading to various environmental impacts."
    )
    clu.save_prompt_knowledge(
        "When explaining complex topics, start with a simple analogy before providing technical details."
    )

    # Perform training
    query = "Explain the potential impacts of climate change on marine ecosystems"
    expected_output = "Climate change affects marine ecosystems through ocean warming, acidification, and sea level rise, leading to habitat loss and species migration."
    training_result = clu.train(
        query, expected_output, OperationalAgentOutput, verbose=True
    )

    console.print("[bold green]Training Result:[/bold green]", training_result)


if __name__ == "__main__":
    example_usage()
